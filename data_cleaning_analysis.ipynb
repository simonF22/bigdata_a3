{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "134a237b",
   "metadata": {},
   "source": [
    "# Data Cleaning and Analysis\n",
    "\n",
    "The stored parquet files for each cateogry (review and meta) will be accessed and merged. Following the merge they will be cleaned and the consolidated into one large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34f5587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext \n",
    "import pyspark\n",
    "from datasets import load_from_disk\n",
    "from pyspark.sql.functions import col, length, trim, when, lit, from_json, split, size, from_unixtime, year, count, avg, countDistinct, first\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import isnan\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import random\n",
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eab02f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3308e028",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    ".master(\"local[*]\") \\\n",
    ".appName(\"Amazon Reviews\") \\\n",
    ".config(\"spark.driver.memory\", \"14g\") \\\n",
    ".config(\"spark.executor.memory\", \"14g\") \\\n",
    ".config(\"spark.local.dir\", \"D:/BigData/spark_temp\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d1334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_categories_cleaned = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332c37df",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = [ \n",
    "    \"All_Beauty\", \"Amazon_Fashion\", \"Appliances\", \"Arts_Crafts_and_Sewing\", \"Automotive\",\n",
    "    \"Baby_Products\", \"Beauty_and_Personal_Care\", \"Books\", \"CDs_and_Vinyl\",\n",
    "    \"Cell_Phones_and_Accessories\", \"Clothing_Shoes_and_Jewelry\", \"Digital_Music\", \"Electronics\",\n",
    "    \"Gift_Cards\", \"Grocery_and_Gourmet_Food\", \"Handmade_Products\", \"Health_and_Household\",\n",
    "    \"Health_and_Personal_Care\", \"Home_and_Kitchen\", \"Industrial_and_Scientific\", \"Kindle_Store\",\n",
    "    \"Magazine_Subscriptions\", \"Movies_and_TV\", \"Musical_Instruments\", \"Office_Products\",\n",
    "    \"Patio_Lawn_and_Garden\", \"Pet_Supplies\", \"Software\", \"Sports_and_Outdoors\",\n",
    "    \"Subscription_Boxes\", \"Tools_and_Home_Improvement\", \"Toys_and_Games\", \"Video_Games\", \"Unknown\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530ec1b",
   "metadata": {},
   "source": [
    "### Function: Assigning the Brand\n",
    "\n",
    "This function will parse the 'details' column for brand or will otherwise extract the brand name from the non-null value in the 'store' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a380c3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_brand(df):\n",
    "    details_schema = StructType([\n",
    "        StructField(\"Brand\", StringType(), True)\n",
    "    ])\n",
    "\n",
    "    df = df.withColumn(\"details_parsed\", from_json(col(\"details\"), details_schema))\n",
    "\n",
    "    df = df.withColumn(\n",
    "        \"brand\",\n",
    "        when(\n",
    "            col(\"details_parsed.Brand\").isNotNull() & (trim(col(\"details_parsed.Brand\")) != \"\"),\n",
    "            trim(col(\"details_parsed.Brand\"))\n",
    "        ).when(\n",
    "            col(\"store\").isNotNull() & (trim(col(\"store\")) != \"\"),\n",
    "            trim(col(\"store\"))\n",
    "        ).otherwise(lit(\"Unknown\"))\n",
    "    )\n",
    "\n",
    "    df = df.drop(\"details_parsed\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669931a",
   "metadata": {},
   "source": [
    "### Function: Cleaning the Dataset\n",
    "\n",
    "This function will combine all the necessary cleaning tasks. It also includes extracting the brand which has its own function call. After the review and meta dataset is merged for each category, this function will be called on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf9b717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    col(\"rating\").isin([1.0, 2.0, 3.0, 4.0, 5.0])\n",
    "    df = df.filter((col(\"text\").isNotNull()) & (length(trim(col(\"text\"))) > 0))\n",
    "    df = set_brand(df)\n",
    "    df = df.dropDuplicates([\"user_id\", \"asin\", \"text\"])\n",
    "    df = df.withColumn(\n",
    "    \"review_length\", \n",
    "    size(split(col(\"text\"), r\"\\s+\"))\n",
    "    )\n",
    "    df = df.withColumn(\n",
    "    \"year\", \n",
    "    when(\n",
    "        col(\"timestamp\").isNotNull(), \n",
    "        year(from_unixtime(col(\"timestamp\") / 1000))\n",
    "    ).otherwise(None)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a71b8314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All_Beauty: cleaned successfully\n",
      "Amazon_Fashion: cleaned successfully\n",
      "Appliances: cleaned successfully\n",
      "Arts_Crafts_and_Sewing: cleaned successfully\n",
      "Automotive: cleaned successfully\n",
      "Baby_Products: cleaned successfully\n",
      "Beauty_and_Personal_Care: cleaned successfully\n",
      "Books: cleaned successfully\n",
      "CDs_and_Vinyl: cleaned successfully\n",
      "Cell_Phones_and_Accessories: cleaned successfully\n",
      "Clothing_Shoes_and_Jewelry: cleaned successfully\n",
      "Digital_Music: cleaned successfully\n",
      "Electronics: cleaned successfully\n",
      "Gift_Cards: cleaned successfully\n",
      "Grocery_and_Gourmet_Food: cleaned successfully\n",
      "Handmade_Products: cleaned successfully\n",
      "Health_and_Household: cleaned successfully\n",
      "Health_and_Personal_Care: cleaned successfully\n",
      "Home_and_Kitchen: cleaned successfully\n",
      "Industrial_and_Scientific: cleaned successfully\n",
      "Kindle_Store: cleaned successfully\n",
      "Magazine_Subscriptions: cleaned successfully\n",
      "Movies_and_TV: cleaned successfully\n",
      "Musical_Instruments: cleaned successfully\n",
      "Office_Products: cleaned successfully\n",
      "Patio_Lawn_and_Garden: cleaned successfully\n",
      "Pet_Supplies: cleaned successfully\n",
      "Software: cleaned successfully\n",
      "Sports_and_Outdoors: cleaned successfully\n",
      "Subscription_Boxes: cleaned successfully\n",
      "Tools_and_Home_Improvement: cleaned successfully\n",
      "Toys_and_Games: cleaned successfully\n",
      "Video_Games: cleaned successfully\n",
      "Unknown: cleaned successfully\n"
     ]
    }
   ],
   "source": [
    "for category in categories:\n",
    "    try:\n",
    "        review_path = f\"D:/BigData/review_parquet_{category}\"\n",
    "        meta_path = f\"D:/BigData/meta_parquet_{category}\"\n",
    "\n",
    "        review_df = spark.read.parquet(review_path)\n",
    "        meta_df = spark.read.parquet(meta_path)\n",
    "\n",
    "        review_df = review_df.withColumnRenamed(\"images\", \"review_images\")\n",
    "        review_df = review_df.withColumnRenamed(\"title\", \"review_title\")\n",
    "        meta_df = meta_df.withColumnRenamed(\"images\", \"meta_images\")\n",
    "        meta_df = meta_df.withColumnRenamed(\"title\", \"meta_title\")\n",
    "\n",
    "        merged_df = review_df.join(meta_df, on=\"parent_asin\", how=\"inner\")\n",
    "\n",
    "        cleaned_df = clean_dataset(merged_df)\n",
    "        all_categories_cleaned.append(cleaned_df)\n",
    "\n",
    "        print(f\"{category}: cleaned successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{category}: failed with error - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84a37636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[parent_asin: string, rating: double, review_title: string, text: string, review_images: array<struct<attachment_type:string,large_image_url:string,medium_image_url:string,small_image_url:string>>, asin: string, user_id: string, timestamp: bigint, helpful_vote: bigint, verified_purchase: boolean, main_category: string, meta_title: string, average_rating: double, rating_number: bigint, features: array<string>, description: array<string>, price: string, meta_images: struct<hi_res:array<string>,large:array<string>,thumb:array<string>,variant:array<string>>, videos: struct<title:array<string>,url:array<string>,user_id:array<string>>, store: string, categories: array<string>, details: string, bought_together: string, subtitle: string, author: string, brand: string, review_length: int, year: int]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_df = reduce(DataFrame.unionByName, all_categories_cleaned)\n",
    "consolidated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319161a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- parent_asin: string (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- review_title: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- review_images: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- attachment_type: string (nullable = true)\n",
      " |    |    |-- large_image_url: string (nullable = true)\n",
      " |    |    |-- medium_image_url: string (nullable = true)\n",
      " |    |    |-- small_image_url: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      " |-- helpful_vote: long (nullable = true)\n",
      " |-- verified_purchase: boolean (nullable = true)\n",
      " |-- main_category: string (nullable = true)\n",
      " |-- meta_title: string (nullable = true)\n",
      " |-- average_rating: double (nullable = true)\n",
      " |-- rating_number: long (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- meta_images: struct (nullable = true)\n",
      " |    |-- hi_res: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- large: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- thumb: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- variant: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- videos: struct (nullable = true)\n",
      " |    |-- title: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- url: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |    |-- user_id: array (nullable = true)\n",
      " |    |    |-- element: string (containsNull = true)\n",
      " |-- store: string (nullable = true)\n",
      " |-- categories: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- details: string (nullable = true)\n",
      " |-- bought_together: string (nullable = true)\n",
      " |-- subtitle: string (nullable = true)\n",
      " |-- author: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- review_length: integer (nullable = false)\n",
      " |-- year: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "consolidated_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a0e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = consolidated_df.select(\"main_category\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "fractions = {cat: 0.1 for cat in categories}\n",
    "\n",
    "sampled_df = consolidated_df.stat.sampleBy(\"main_category\", fractions, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d0c2ab",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5f290",
   "metadata": {},
   "source": [
    "Rating Histogram for ratings 1–5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a854f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_histogram = (\n",
    "    consolidated_df\n",
    "    .filter(col(\"rating\").between(1, 5))\n",
    "    .groupBy(\"rating\")\n",
    "    .count()\n",
    "    .orderBy(\"rating\")\n",
    ")\n",
    "\n",
    "rating_histogram.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a06487",
   "metadata": {},
   "source": [
    "Bar chart of categories by total review count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c80b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_counts = (\n",
    "    consolidated_df\n",
    "    .filter(col(\"main_category\").isNotNull())\n",
    "    .groupBy(\"main_category\")\n",
    "    .count()\n",
    "    .orderBy(\"count\", ascending=False)\n",
    ")\n",
    "\n",
    "category_counts.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f3a02",
   "metadata": {},
   "source": [
    "Bar chart of brand by total review count excluding “Unknown” from the top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67251161",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_counts = (\n",
    "    consolidated_df\n",
    "    .filter((col(\"brand\").isNotNull()) & (col(\"brand\") != \"Unknown\"))\n",
    "    .groupBy(\"brand\")\n",
    "    .count()\n",
    "    .orderBy(\"count\", ascending=False)\n",
    ")\n",
    "\n",
    "brand_counts.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6647d5c1",
   "metadata": {},
   "source": [
    "Time-Based Trend: a line chart of average star rating per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb380eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating_by_year = (\n",
    "    consolidated_df\n",
    "    .filter(col(\"year\").isNotNull() & col(\"rating\").isNotNull())\n",
    "    .groupBy(\"year\")\n",
    "    .agg(avg(\"rating\").alias(\"avg_rating\"))\n",
    "    .orderBy(\"year\")\n",
    ")\n",
    "\n",
    "avg_rating_by_year.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0f2e66",
   "metadata": {},
   "source": [
    "Pearson correlation between review length and star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = consolidated_df.stat.corr(\"review_length\", \"rating\")\n",
    "print(f\"Pearson correlation between review length and rating: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a01046",
   "metadata": {},
   "source": [
    "##  Binary Sentiment Prediction (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec638266",
   "metadata": {},
   "source": [
    "A label column will be created to represent positive (1) if rating > 3, otherwise negative (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e04a0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df = consolidated_df.withColumn(\"label\", when(col(\"rating\") > 3, 1).otherwise(0)) \\\n",
    "                     .select(\"text\", \"label\") \\\n",
    "                     .filter(col(\"text\").isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001970c7",
   "metadata": {},
   "source": [
    "Train/Test Split: 80/20 split, random shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a2f2452",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = labeled_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80482e",
   "metadata": {},
   "source": [
    "TF-IDF on review text (lowercase, split on whitespace/punctuation), discarding tokens in fewer than 5 reviews or in over 80% of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8193f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_tokenizer = RegexTokenizer(inputCol=\"text\", outputCol=\"tokens\", pattern=\"\\\\W\")\n",
    "\n",
    "stop_remover = StopWordsRemover(inputCol=\"tokens\", outputCol=\"filtered_tokens\")\n",
    "\n",
    "count_vectorizer = CountVectorizer(inputCol=\"filtered_tokens\", outputCol=\"raw_features\",\n",
    "                                   minDF=5.0, maxDF=0.8)\n",
    "\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5649b",
   "metadata": {},
   "source": [
    "Classifier: Logistic Regression (default hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "364887ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a1147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[regex_tokenizer, stop_remover, count_vectorizer, idf, lr])\n",
    "model = pipeline.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe1ca93",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c14aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test_df)\n",
    "\n",
    "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator_acc.evaluate(predictions)\n",
    "\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "f1_score = evaluator_f1.evaluate(predictions)\n",
    "\n",
    "preds_rdd = predictions.select(\"prediction\", \"label\").rdd.map(tuple)\n",
    "metrics = MulticlassMetrics(preds_rdd)\n",
    "\n",
    "conf_matrix = metrics.confusionMatrix().toArray()\n",
    "TP = int(conf_matrix[1][1])\n",
    "FP = int(conf_matrix[0][1])\n",
    "TN = int(conf_matrix[0][0])\n",
    "FN = int(conf_matrix[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b0f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"TP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94326ef4",
   "metadata": {},
   "source": [
    "## Recommender (ALS)\n",
    "Creating a collaborative filtering model using Alternating Least Squares (ALS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c291620f",
   "metadata": {},
   "source": [
    "Data Setup: Retain (user id, product id,rating). Drop users with fewer than 5 total reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_review_counts = consolidated_df.groupBy(\"user_id\").agg(count(\"rating\").alias(\"review_count\"))\n",
    "filtered_users = user_review_counts.filter(\"review_count >= 5\").select(\"user_id\")\n",
    "\n",
    "als_data = consolidated_df.select(\"user_id\", \"asin\", \"rating\") \\\n",
    "                   .join(filtered_users, on=\"user_id\", how=\"inner\") \\\n",
    "                   .filter(col(\"rating\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a4a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"userIndex\").fit(als_data)\n",
    "item_indexer = StringIndexer(inputCol=\"asin\", outputCol=\"itemIndex\").fit(als_data)\n",
    "\n",
    "train_indexed = user_indexer.transform(train_df)\n",
    "train_indexed = item_indexer.transform(train_indexed)\n",
    "\n",
    "test_indexed = user_indexer.transform(test_df)\n",
    "test_indexed = item_indexer.transform(test_indexed)\n",
    "\n",
    "als = ALS(userCol=\"userIndex\", itemCol=\"itemIndex\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\", nonnegative=True)\n",
    "\n",
    "als_model = als.fit(train_indexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ab5ada",
   "metadata": {},
   "source": [
    "Evaluation: RMSE on the test set (predicted rating vs. actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = als_model.transform(test_indexed)\n",
    "\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"RMSE on test data: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9093b4",
   "metadata": {},
   "source": [
    "Demo: Show top 5 recommendations for 3 random users in the test set, including predicted ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73187a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_users = test_indexed.select(\"userIndex\").distinct().rdd.map(lambda r: r[0]).collect()\n",
    "sample_users = random.sample(test_users, 3)\n",
    "\n",
    "user_subset = spark.createDataFrame([(uid,) for uid in sample_users], [\"userIndex\"])\n",
    "user_recs = als_model.recommendForUserSubset(user_subset, 5)\n",
    "\n",
    "user_recs.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe526c7a",
   "metadata": {},
   "source": [
    "## Clustering / Segmentation (k-means)\n",
    "Segmentation of products using k-means with k = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b15f092",
   "metadata": {},
   "source": [
    "Features (per product): (mean rating, total reviews, brand id, category id)\n",
    "- mean rating: Average user rating per product (based on your merged data, not necessarily average rating from metadata, though you could compare them.)\n",
    "- total reviews: Count of all reviews for that product\n",
    "- brand id: Map each distinct brand string to an integer\n",
    "- category id: Map each main category or top-level category string to an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae052e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_features = consolidated_df.groupBy(\"asin\").agg(\n",
    "    avg(\"rating\").alias(\"mean_rating\"),\n",
    "    count(\"rating\").alias(\"total_reviews\"),\n",
    "    countDistinct(\"user_id\").alias(\"unique_users\"),\n",
    "    avg(\"average_rating\").alias(\"avg_meta_rating\"),\n",
    "    count(\"review_title\").alias(\"title_count\"),\n",
    "    first(\"brand\").alias(\"brand\"),\n",
    "    first(\"main_category\").alias(\"main_category\")\n",
    ").filter(col(\"mean_rating\").isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395c971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_indexer = StringIndexer(inputCol=\"brand\", outputCol=\"brand_id\", handleInvalid=\"keep\").fit(product_features)\n",
    "category_indexer = StringIndexer(inputCol=\"main_category\", outputCol=\"category_id\", handleInvalid=\"keep\").fit(product_features)\n",
    "\n",
    "indexed_df = brand_indexer.transform(product_features)\n",
    "indexed_df = category_indexer.transform(indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"mean_rating\", \"total_reviews\", \"brand_id\", \"category_id\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "feature_df = assembler.transform(indexed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c656b8",
   "metadata": {},
   "source": [
    "k-means: Exactly k = 5, default initialization, until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c88ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(featuresCol=\"features\", predictionCol=\"cluster\", k=5, seed=42)\n",
    "kmeans_model = kmeans.fit(feature_df)\n",
    "clustered_df = kmeans_model.transform(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26757529",
   "metadata": {},
   "source": [
    "Cluster Analysis (for each cluster)\n",
    "- Size: number of products in the cluster\n",
    "- Average mean rating, average total reviews\n",
    "- Average brand id and category id\n",
    "- A short interpretation (e.g., high-rating electronics, unknown-brand items, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be5d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary = clustered_df.groupBy(\"cluster\").agg(\n",
    "    count(\"asin\").alias(\"num_products\"),\n",
    "    avg(\"mean_rating\").alias(\"avg_rating\"),\n",
    "    avg(\"total_reviews\").alias(\"avg_reviews\"),\n",
    "    avg(\"brand_id\").alias(\"avg_brand_id\"),\n",
    "    avg(\"category_id\").alias(\"avg_category_id\")\n",
    ").orderBy(\"cluster\")\n",
    "\n",
    "cluster_summary.show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
